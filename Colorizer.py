# -*- coding: utf-8 -*-
"""Copie_de_Image_Colorization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VN_JHvz0pLBz71MWU7J-y599_rySh_tH
"""

# Commented out IPython magic to ensure Python compatibility.
# For plotting
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
# For conversion
from skimage.color import lab2rgb, rgb2lab, rgb2gray
from skimage import io
# For everything
import torch
import torch.nn as nn
import torch.nn.functional as F
# For our model
import torchvision.models as models
from torchvision import datasets, transforms
# For utilities
import os, shutil, time

from google.colab import files
uploaded = files.upload()  # Choisis dataset.zip dans ton explorateur de fichiers

import zipfile


zip_path = 'dataset.zip'
extract_path = 'dataset'

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

use_gpu = torch.cuda.is_available()
use_gpu

class ColorizationNet(nn.Module):
  def __init__(self, input_size=128):
    super(ColorizationNet, self).__init__()
    MIDLEVEL_FEATURE_SIZE = 128

    ## First half: ResNet
    resnet = models.resnet18(num_classes=365)
    # Change first conv layer to accept single-channel (grayscale) input
    resnet.conv1.weight = nn.Parameter(resnet.conv1.weight.sum(dim=1).unsqueeze(1))
    # Extract midlevel features from ResNet-gray
    self.midlevel_resnet = nn.Sequential(*list(resnet.children())[0:6])

    ## Second half: Upsampling
    self.upsample = nn.Sequential(
      nn.Conv2d(MIDLEVEL_FEATURE_SIZE, 128, kernel_size=3, stride=1, padding=1),
      nn.BatchNorm2d(128),
      nn.ReLU(),
      nn.Upsample(scale_factor=2),
      nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),
      nn.BatchNorm2d(64),
      nn.ReLU(),
      nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),
      nn.BatchNorm2d(64),
      nn.ReLU(),
      nn.Upsample(scale_factor=2),
      nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),
      nn.BatchNorm2d(32),
      nn.ReLU(),
      nn.Conv2d(32, 2, kernel_size=3, stride=1, padding=1),
      nn.Upsample(scale_factor=2)
    )

  def forward(self, input):

    # Pass input through ResNet-gray to extract features
    midlevel_features = self.midlevel_resnet(input)

    # Upsample to get colors
    output = self.upsample(midlevel_features)
    return output

model = ColorizationNet()

criterion = nn.MSELoss()

optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.0)

class GrayscaleImageFolder(datasets.ImageFolder):
  '''Custom images folder, which converts images to grayscale before loading'''
  def __getitem__(self, index):
    path, target = self.imgs[index]
    img = self.loader(path)
    if self.transform is not None:
      img_original = self.transform(img)
      img_original = np.asarray(img_original)
      img_lab = rgb2lab(img_original)
      img_lab = (img_lab + 128) / 255
      img_ab = img_lab[:, :, 1:3]
      img_ab = torch.from_numpy(img_ab.transpose((2, 0, 1))).float()
      img_original = rgb2gray(img_original)
      img_original = torch.from_numpy(img_original).unsqueeze(0).float()
    if self.target_transform is not None:
      target = self.target_transform(target)
    return img_original, img_ab, target

# Training
train_transforms = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224), transforms.RandomHorizontalFlip()])
train_imagefolder = GrayscaleImageFolder('/content/dataset/dataset/train', train_transforms)
train_loader = torch.utils.data.DataLoader(train_imagefolder, batch_size=32, shuffle=True)

# Validation
val_transforms = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224)])
val_imagefolder = GrayscaleImageFolder('/content//dataset/dataset/validation' , val_transforms)
val_loader = torch.utils.data.DataLoader(val_imagefolder, batch_size=10, shuffle=False)

class AverageMeter(object):
  '''A handy class from the PyTorch ImageNet tutorial'''
  def __init__(self):
    self.reset()
  def reset(self):
    self.val, self.avg, self.sum, self.count = 0, 0, 0, 0
  def update(self, val, n=1):
    self.val = val
    self.sum += val * n
    self.count += n
    self.avg = self.sum / self.count

def to_rgb(grayscale_input, ab_input, save_path=None, save_name=None):
  '''Show/save rgb image from grayscale and ab channels
     Input save_path in the form {'grayscale': '/path/', 'colorized': '/path/'}'''
  plt.clf() # clear matplotlib
  color_image = torch.cat((grayscale_input, ab_input), 0).numpy() # combine channels
  color_image = color_image.transpose((1, 2, 0))  # rescale for matplotlib
  color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100
  color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128
  color_image = lab2rgb(color_image.astype(np.float64))
  grayscale_input = grayscale_input.squeeze().numpy()
  if save_path is not None and save_name is not None:
    plt.imsave(arr=grayscale_input, fname='{}{}'.format(save_path['grayscale'], save_name), cmap='gray')
    plt.imsave(arr=color_image, fname='{}{}'.format(save_path['colorized'], save_name))

def validate(val_loader, model, criterion, save_images, epoch):
  model.eval()

  # Prepare value counters and timers
  batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()

  end = time.time()
  already_saved_images = False
  for i, (input_gray, input_ab, target) in enumerate(val_loader):
    data_time.update(time.time() - end)

    # Use GPU
    if use_gpu: input_gray, input_ab, target = input_gray.cuda(), input_ab.cuda(), target.cuda()

    # Run model and record loss
    output_ab = model(input_gray) # throw away class predictions
    loss = criterion(output_ab, input_ab)
    losses.update(loss.item(), input_gray.size(0))

    # Save images to file
    if save_images and not already_saved_images:
      already_saved_images = True
      for j in range(min(len(output_ab), 10)): # save at most 5 images
        save_path = {'grayscale': 'outputs/gray/', 'colorized': 'outputs/color/'}
        save_name = 'img-{}-epoch-{}.jpg'.format(i * val_loader.batch_size + j, epoch)
        to_rgb(input_gray[j].cpu(), ab_input=output_ab[j].detach().cpu(), save_path=save_path, save_name=save_name)

    # Record time to do forward passes and save images
    batch_time.update(time.time() - end)
    end = time.time()

    # Print model accuracy -- in the code below, val refers to both value and validation
    if i % 25 == 0:
      print('Validate: [{0}/{1}]\t'
            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\t'
            'Loss {loss.val:.4f} ({loss.avg:.4f})\t'.format(
             i, len(val_loader), batch_time=batch_time, loss=losses))

  print('Finished validation.')
  return losses.avg

def train(train_loader, model, criterion, optimizer, epoch):
  print('Starting training epoch {}'.format(epoch))
  model.train()

  # Prepare value counters and timers
  batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()

  end = time.time()
  for i, (input_gray, input_ab, target) in enumerate(train_loader):

    # Use GPU if available
    if use_gpu: input_gray, input_ab, target = input_gray.cuda(), input_ab.cuda(), target.cuda()

    # Record time to load data (above)
    data_time.update(time.time() - end)

    # Run forward pass
    output_ab = model(input_gray)
    loss = criterion(output_ab, input_ab)
    losses.update(loss.item(), input_gray.size(0))

    # Compute gradient and optimize
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # Record time to do forward and backward passes
    batch_time.update(time.time() - end)
    end = time.time()

    # Print model accuracy -- in the code below, val refers to value, not validation
    if i % 25 == 0:
      print('Epoch: [{0}][{1}/{2}]\t'
            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\t'
            'Data {data_time.val:.3f} ({data_time.avg:.3f})\t'
            'Loss {loss.val:.4f} ({loss.avg:.4f})\t'.format(
              epoch, i, len(train_loader), batch_time=batch_time,
             data_time=data_time, loss=losses))

  print('Finished training epoch {}'.format(epoch))
  return losses.avg  # <-- ajout ici

# Move model and loss function to GPU
if use_gpu:
  criterion = criterion.cuda()
  model = model.cuda()

# Make folders and set parameters
os.makedirs('outputs/color', exist_ok=True)
os.makedirs('outputs/gray', exist_ok=True)
os.makedirs('checkpoints', exist_ok=True)
save_images = True
best_losses = 1e10
epochs = 1000

# Train model
train_losses = []
val_losses = []

for epoch in range(epochs):
  train(train_loader, model, criterion, optimizer, epoch)
  train_loss = train(train_loader, model, criterion, optimizer, epoch)
  with torch.no_grad():
    val_loss = validate(val_loader, model, criterion, save_images, epoch)

    train_losses.append(train_loss)
    val_losses.append(val_loss)


  if val_loss < best_losses:
    best_losses = val_loss
    torch.save(model.state_dict(), 'checkpoints/model-epoch-{}-losses-{:.3f}.pth'.format(epoch+1, val_loss))

plt.figure(figsize=(10, 5))
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Courbes de Loss')
plt.legend()
plt.grid(True)
plt.show()

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import cv2
# For conversion
from skimage.color import lab2rgb, rgb2lab, rgb2gray
from skimage import io
# For everything
import torch
import torch.nn as nn
import torch.nn.functional as F
# For our model
import torchvision.models as models
from torchvision import datasets, transforms
# For utilities
from torchsummary import summary
from math import log10, sqrt

device = 'cuda:0' if torch.cuda.is_available() else 'cpu'

class ColorizationNet(nn.Module):
  def __init__(self, input_size=128):
    super(ColorizationNet, self).__init__()
    MIDLEVEL_FEATURE_SIZE = 128

    ## First half: ResNet
    resnet = models.resnet18(num_classes=365)
    # Change first conv layer to accept single-channel (grayscale) input
    resnet.conv1.weight = nn.Parameter(resnet.conv1.weight.sum(dim=1).unsqueeze(1))
    # Extract midlevel features from ResNet-gray
    self.midlevel_resnet = nn.Sequential(*list(resnet.children())[0:6])

    ## Second half: Upsampling
    self.upsample = nn.Sequential(
      nn.Conv2d(MIDLEVEL_FEATURE_SIZE, 128, kernel_size=3, stride=1, padding=1),
      nn.BatchNorm2d(128),
      nn.ReLU(),
      nn.Upsample(scale_factor=2),
      nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),
      nn.BatchNorm2d(64),
      nn.ReLU(),
      nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),
      nn.BatchNorm2d(64),
      nn.ReLU(),
      nn.Upsample(scale_factor=2),
      nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),
      nn.BatchNorm2d(32),
      nn.ReLU(),
      nn.Conv2d(32, 2, kernel_size=3, stride=1, padding=1),
      nn.Upsample(scale_factor=2)
    )

  def forward(self, input):

    # Pass input through ResNet-gray to extract features
    midlevel_features = self.midlevel_resnet(input)

    # Upsample to get colors
    output = self.upsample(midlevel_features)
    return output

model = ColorizationNet().to(device)

model.load_state_dict(torch.load('/content/checkpoints/model-epoch-294-losses-0.002.pth'))

summary(model, input_size = (1, 128, 128), batch_size = -1)

class GrayscaleImageFolder(datasets.ImageFolder):
    def __getitem__(self, index):
        path, target = self.imgs[index]
        img = self.loader(path)
        if self.transform is not None:
            img_transformed = self.transform(img)
            img_np = np.asarray(img_transformed)  # RGB image (HxWx3)

            # Save RGB image normalized between 0 and 1
            img_rgb = img_np.astype(np.float32) / 255.0

            # Convert to Lab
            img_lab = rgb2lab(img_np)
            img_lab = (img_lab + 128) / 255

            # Extract ab channels
            img_ab = img_lab[:, :, 1:3]
            img_ab = torch.from_numpy(img_ab.transpose((2, 0, 1))).float()

            # Convert to grayscale
            img_gray = rgb2gray(img_np)
            img_gray = torch.from_numpy(img_gray).unsqueeze(0).float()
        if self.target_transform is not None:
            target = self.target_transform(target)

        return img_gray, img_ab, torch.from_numpy(img_rgb.transpose((2, 0, 1))).float()

def PSNR(original, compressed):
    mse = np.mean((original - compressed) ** 2)
    if(mse == 0):  # MSE is zero means no noise is present in the signal .
                  # Therefore PSNR have no importance.
        return 100
    max_pixel = 255.0
    psnr = 20 * log10(max_pixel / sqrt(mse))
    return psnr

def to_rgb(grayscale_input, ab_predicted, ground_truth_rgb):
    plt.clf()

    # Recomposer la prédiction couleur
    color_image = torch.cat((grayscale_input, ab_predicted), dim=0).numpy()
    color_image = color_image.transpose((1, 2, 0))
    color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100
    color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128
    color_image = lab2rgb(color_image.astype(np.float64))

    # Mise en forme
    grayscale_display = grayscale_input.squeeze().numpy()
    ground_truth_rgb = ground_truth_rgb.permute(1, 2, 0).numpy()  # (H, W, 3)

    # Affichage
    fig = plt.figure(figsize=(12, 10))
    fig.subplots_adjust(hspace=0.1, wspace=0.2)

    ax = fig.add_subplot(1, 3, 1)
    ax.set_title('Input (Grayscale)')
    ax.imshow(grayscale_display, cmap='gray')
    ax.axis("off")

    ax = fig.add_subplot(1, 3, 2)
    ax.set_title('Ground Truth (Original RGB)')
    ax.imshow(ground_truth_rgb)
    ax.axis("off")

    ax = fig.add_subplot(1, 3, 3)
    ax.set_title('Predicted Value')
    ax.imshow(color_image)
    ax.axis("off")

    # Affiche la PSNR entre l'image générée et l'originale
    psnr_val = "PSNR: " + str(PSNR(ground_truth_rgb, color_image))
    print(psnr_val)

use_gpu = torch.cuda.is_available()

test_transforms = transforms.Compose([transforms.Resize(224),transforms.CenterCrop(224)])
testset = GrayscaleImageFolder('/content/dataset/dataset/test', test_transforms)
dataloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=True)

test_transforms2 = transforms.Compose([transforms.Resize(224),transforms.CenterCrop(224),
                                transforms.ToTensor()])
testset2 = datasets.ImageFolder('/content/dataset/dataset/test', transform=test_transforms2)
dataloader2 = torch.utils.data.DataLoader(testset2, batch_size=1, shuffle=True)
images, labels = next(iter(dataloader2))
image = images[0].numpy().transpose((1, 2, 0))

for i, (input_gray, input_ab, ground_truth_rgb) in enumerate(dataloader):
    if use_gpu:
        input_gray = input_gray.cuda()

    output_ab = model(input_gray)

    for j in range(min(len(output_ab), 10)):
        to_rgb(input_gray[j].cpu(), output_ab[j].cpu().detach(), ground_truth_rgb[j].cpu())

model.eval()
with torch.no_grad():
    for i, (input_gray, input_ab, target_rgb) in enumerate(val_loader):
        if i >= 5:
            break

        if use_gpu:
            input_gray = input_gray.cuda()
            input_ab = input_ab.cuda()

        # Prédiction
        output_ab = model(input_gray)

        # Appel à ta fonction d'affichage
        to_rgb(input_gray[0].cpu(),
               output_ab[0].cpu(),
               target_rgb[0].cpu())